{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework7_SavantaComresWebScraperipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjVAtQJR4SSX"
      },
      "source": [
        "# SavantaComres Polling Data Web Scraper\n",
        "\n",
        "# Edward Natusch University of Bristol 2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qgQLkuS4iQw"
      },
      "source": [
        "# Importing the required packages \n",
        "\n",
        "import certifi\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from urllib.request import Request, urlopen\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import requests\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRWbcZsL4mbu"
      },
      "source": [
        "# Using beautiful soup to read the html data from comresglobal\n",
        "\n",
        "url = 'https://comresglobal.com/poll-category/voting-intention/'\n",
        "\n",
        "request = Request(url , headers ={'User-Agent':'Mozilla/5.0'})\n",
        "\n",
        "html = urlopen(request).read()\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah6i-3Ai4rZG"
      },
      "source": [
        "# Creating an array 'links' to store the links found in the html data \n",
        "\n",
        "links = []\n",
        "\n",
        "for link in soup.find_all('a'):\n",
        "   links.append(link.get('href'))\n",
        "\n",
        "# Creating an array 'VotingIntentionLinks' to store all the links, which include Westminster Voting Intention data\n",
        "\n",
        "VotingIntentionLinks= []\n",
        "\n",
        "for i in range(0,len(links)):\n",
        "  if '/westminster-voting-intention-' in links[i]:\n",
        "    VotingIntentionLinks.append(links[i])\n",
        "    print(links[i])\n",
        "\n",
        "# Creating two arrays 'Polls' and 'Text' to hold \n",
        "\n",
        "Polls = []\n",
        "\n",
        "Text = []\n",
        "\n",
        "# Looping through all the Westminster Voting Intention links and storing the text data in the array 'Polls'\n",
        "\n",
        "for i in range(0,len(VotingIntentionLinks)):\n",
        "  url = (VotingIntentionLinks[i])\n",
        "  request = Request(url , headers ={'User-Agent':'Mozilla/5.0'})\n",
        "  html = urlopen(request).read()\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  soup_li = soup.find_all(\"div\", {\"class\": \"col-md-7\"})\n",
        "  Polls.append(soup_li[0].text)\n",
        "  print(soup_li[0].text)\n",
        "\n",
        "# Creating a variable "a" to store the length of the array 'Polls'\n",
        "\n",
        "a = len(Polls)\n",
        "\n",
        "\n",
        "# Extracting polling data for the conservative party \n",
        "\n",
        "count = 0\n",
        "found = False\n",
        "\n",
        "# Creating three arrays. The first stores the polling value, the second stores the date the poll was published and the third will store that these values are for the Conservatives.\n",
        "\n",
        "Conservative_poll_values = []\n",
        "Conservative_poll_dates = []\n",
        "Conservative_Party = []\n",
        "\n",
        "# For loop, loops through the text data, looking for a match for 'Con' and stores the value of the polling data in the array 'Conservative_poll_values'\n",
        "\n",
        "# Additionally, looks for a match with 'Date Published' and stores the date in the array 'Conservative_poll_dates' \n",
        "\n",
        "for i in range(0,a):\n",
        "  b=len(Polls[i])\n",
        "  found = False\n",
        "  for j in range(0,b):\n",
        "    if((Polls[i][j] =='C' and Polls[i][j+1] == 'o'and Polls[i][j+2] == 'n' and Polls[i][j+3] == ' ' and Polls[i][j+4] != 'v') or (Polls[i][j] =='C' and Polls[i][j+1] == 'O'and Polls[i][j+2] == 'N' and Polls[i][j+3] != 'T')):\n",
        "      print(Polls[i][j+4:j+8])\n",
        "      Conservative_poll_values.append(Polls[i][j+4:j+8])\n",
        "      Conservative_Party.append(\"Conservative\")\n",
        "      count = count + 1\n",
        "      found = True\n",
        "    \n",
        "    # Following two lines commented out - Work in Progress \n",
        "\n",
        "    # if((found == True) and (Polls[i][j:j+11] == 'online from')):\n",
        "       # print(Polls[i][j+12:j+34])\n",
        "    \n",
        "    # if((found == True) and (Polls[i][j:j+14] == 'online between')):\n",
        "      # print(Polls[i][j+15:j+36])\n",
        "\n",
        "    if((found == True) and (Polls[i][j:j+14] == 'Date Published')):\n",
        "      Conservative_poll_dates.append(Polls[i][j+15:j+25])\n",
        "  \n",
        "\n",
        "# Doing the same for Labour \n",
        "\n",
        "count = 0\n",
        "found = False\n",
        "\n",
        "Labour_poll_values = []\n",
        "Labour_poll_dates = []\n",
        "Labour_Party = []\n",
        "\n",
        "for i in range(0,a):\n",
        "  b=len(Polls[i])\n",
        "  found = False\n",
        "  for j in range(0,b):\n",
        "    if(Polls[i][j] == ('L') and (Polls[i][j+1] == 'A') and (Polls[i][j+2] == 'B')) or (Polls[i][j] == ('L') and (Polls[i][j+1] == 'a') and (Polls[i][j+2] == 'b') and Polls[i][j+3] == ' '):\n",
        "      print(Polls[i][j+4:j+8])\n",
        "      Labour_poll_values.append(Polls[i][j+4:j+8])\n",
        "      Labour_Party.append(\"Labour\")\n",
        "      count = count + 1\n",
        "      found = True\n",
        "\n",
        "    if((found == True) and (Polls[i][j:j+14] == 'Date Published')):\n",
        "      Labour_poll_dates.append(Polls[i][j+15:j+25])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6orU3yAa4yV2"
      },
      "source": [
        "# Inputting the scraped polling data into a table and cleaning\n",
        "\n",
        "# Creating a data frame to store Conservative party data\n",
        "\n",
        "df1 = pd.DataFrame([Conservative_Party,Conservative_poll_values,Conservative_poll_dates]).T\n",
        "df1.columns = ['Party','Vote Percentage','Date']\n",
        "\n",
        "# Cleaning the data\n",
        "\n",
        "df1['Vote Percentage'] = df1['Vote Percentage'].str.replace('(',' ')\n",
        "df1['Vote Percentage'] = df1['Vote Percentage'].str.replace('%',' ')\n",
        "df1['Vote Percentage'] = df1['Vote Percentage'].str.replace('\\n',' ')\n",
        "df1['Vote Percentage'] = df1['Vote Percentage'].str.replace('-',' ')\n",
        "df1['Date'] = df1['Date'].str.replace('\\n',' ')\n",
        "\n",
        "# Creating a data frame to store Labour party data\n",
        "\n",
        "df2 = pd.DataFrame([Labour_Party,Labour_poll_values,Labour_poll_dates]).T\n",
        "df2.columns = ['Party','Vote Percentage','Date']\n",
        "df2['Vote Percentage'] = df2['Vote Percentage'].str.replace('(',' ')\n",
        "df2['Vote Percentage'] = df2['Vote Percentage'].str.replace('%',' ')\n",
        "df2['Vote Percentage'] = df2['Vote Percentage'].str.replace('\\n',' ')\n",
        "df2['Vote Percentage'] = df2['Vote Percentage'].str.replace('-',' ')\n",
        "df2['Date'] = df2['Date'].str.replace('\\n',' ')\n",
        "\n",
        "# Sort by publishing date\n",
        "\n",
        "df1[\"Date\"] = pd.to_datetime(df1[\"Date\"],dayfirst=True)\n",
        "df2[\"Date\"] = pd.to_datetime(df2[\"Date\"],dayfirst=True)\n",
        "\n",
        "df1.sort_values(by=['Date'], inplace=True)\n",
        "df2.sort_values(by=['Date'], inplace=True)\n",
        "\n",
        "df1.to_csv(\"Homework7_ConservativePartyPollingData.csv\")\n",
        "df2.to_csv(\"Homework7_LabourPartyPollingData.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
